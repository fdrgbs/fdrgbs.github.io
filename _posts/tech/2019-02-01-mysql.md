---
layout: post
title: MySQL的常规总结
date: 2019-02-01
category: 技术
tags: [mysql]
keywords: mysql,log
---

# 故障恢复

*************

## Force and Steal

```

从上面看出，Redo和Undo内容分别可以保证Durability和Atomic两个特性，其中一种信息的缺失需要用严格的刷盘顺序来弥补。这里关注的刷盘顺序包含两个维度：

Force or No-Force：Commit时是否需要强制刷盘，采用Force的方式由于所有的已提交事务的数据一定已经存在于磁盘，自然而然地保证了Durability；
No-Steal or Steal，Commit前数据是否可以提前刷盘，采用No-Steal的方式由于保证事务提交前修改不会出现在磁盘上，自然而然地保证了Atomic。
总结一下，实现Durability可以通过记录Redo信息或要求Force刷盘顺序，实现Atomic需要记录Undo信息或要求No-Steal刷盘顺序，组合得到如下四种模式，如下图所示：

```

quadrant




## Undo-Only Logging

* 落盘顺序为Log记录->Data->Commit标记

##Redo-Only Logging

* 落盘顺序为Log记录->Commit标记->Data

## Redo-Undo Logging

```

可以看出的只有Undo或Redo的问题，主要来自于对Commit标记及Data落盘顺序的限制，而这种限制归根结底来源于Log信息中对新值或旧值的缺失。因此Redo-Undo采用同时记录新值和旧值的方式，来消除Commit和Data之间刷盘顺序的限制。

Durability of Updates：Redo 内容保证，已提交事务的未刷盘的修改，利用Redo Log中的内容重放，之后可见；
Failure Atomic：Undo内容保证，失败事务的已刷盘的修改会在恢复阶段通过Undo日志回滚，不再可见。
如此一来，同Page的不同事务提交就变得非常简单。同时可以将连续的数据攒着进行批量的刷盘已利用磁盘较高的顺序写性能。

```
*********************

## 调优

```

show variables like '%max_connect%';



show status like 'Threads%';



show variables like 'open_files_limit';



 SHOW GLOBAL STATUS like '%sort%';



show global status like 'binlog_cache%';



show status like '%threads%';



show status like 'connections';



show status like 'Created_tmp_%';



show status like 'innodb%';

```



## 生态

### MGR

* MySQL Group Replication-MGR-基于[Paxos]协议的状态机复制

 **无损半同步复制（lossless semi-sync replication

* MongoDB、TiDB这些出现的后起之后通过[Raft]协议来进行选主，从而避免脑裂问题的产生。然而他们依然是单写的场景，即一个高可用集群下，写入依然是单个节点

* Quorum原则（大部分原则）只是Paxos实现的一小部分



*************

## 常用

 * show plugins

 * show processlist



## 参数

* max_allowed_packet - 前后端交互内容的最大限制

## binglog格式

* row - 每一行记录

* mixed -- mix

* statement -- 关注上下文

##事务

* 脏读 （读到未提交）

* 不可重复度 （数据值不同）

* 幻读 （个数不同）

*********

* 读取未提交-RUC

* 读取已提交-RC

    1.锁住未满足行，语句执行完，即可释放锁，不需要关注事务

* 可重复读-RR

    1.事务开始时，创建快照 ReadView

    2.存在间隙锁，避免幻读

* 序列化读-S





## Alter

* 一般来说，建议把多个alter语句合并在一起进行，避免多次table rebuild带来的消耗。但是也要注意分组，比如需要copy table和只需inplace就能完成的，应该分两个alter语句。



## Online ddl


online ddl主要包括3个阶段，prepare阶段，ddl执行阶段，commit阶段，rebuild方式比no-rebuild方式实质多了一个ddl执行阶段，prepare阶段和commit阶段类似。下面将主要介绍ddl执行过程中三个阶段的流程。

* Prepare阶段 :

创建新的临时frm文件(与InnoDB无关)
持有EXCLUSIVE-MDL锁，禁止读写
根据alter类型，确定执行方式(copy,online-rebuild,online-norebuild)
假如是Add Index，则选择online-norebuild即INPLACE方式
更新数据字典的内存对象
分配row_log对象记录增量(仅rebuild类型需要)
生成新的临时ibd文件(仅rebuild类型需要)
* ddl执行阶段 :

降级EXCLUSIVE-MDL锁，允许读写
扫描old_table的聚集索引每一条记录rec
遍历新表的聚集索引和二级索引，逐一处理
根据rec构造对应的索引项
将构造索引项插入sort_buffer块排序
将sort_buffer块更新到新的索引上
记录ddl执行过程中产生的增量(仅rebuild类型需要)
重放row_log中的操作到新索引上(no-rebuild数据是在原表上更新的)
重放row_log间产生dml操作append到row_log最后一个Block
* commit阶段 :

当前Block为row_log最后一个时，禁止读写，升级到EXCLUSIVE-MDL锁
重做row_log中最后一部分增量
更新innodb的数据字典表
提交事务(刷事务的redo日志)
修改统计信息
rename临时idb文件，frm文件
变更完成
这有一直导图挺直观的：http://blog.itpub.net/22664653/viewspace-2056953 。
    * 添加列 时由于需要copy table，row_log会重放到新表上（临时ibd文件），直到最后一个block，锁住原表禁止更新。

row_log记录了ddl变更过程中新产生的dml操作，并在ddl执行的最后将其应用到新的表中，保证数据完整性


